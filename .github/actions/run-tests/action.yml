name: 'Run Tests'
description: 'Run Go tests with configurable options'

inputs:
  test-type:
    description: 'Type of tests to run (unit, integration, e2e, all)'
    required: true
  go-version:
    description: 'Go version to use'
    required: false
    default: '1.24'
  coverage:
    description: 'Enable coverage reporting'
    required: false
    default: 'false'
  race-detection:
    description: 'Enable race detection'
    required: false
    default: 'false'
  timeout:
    description: 'Test timeout'
    required: false
    default: '10m'
  parallel:
    description: 'Number of parallel test processes'
    required: false
    default: '4'
  test-tags:
    description: 'Build tags for tests'
    required: false
    default: ''
  upload-coverage:
    description: 'Upload coverage to Codecov'
    required: false
    default: 'false'
  vault-version:
    description: 'Vault version for integration tests'
    required: false
    default: ''
  k3s-version:
    description: 'K3s version for integration tests'
    required: false
    default: ''

outputs:
  result:
    description: 'Test result (success/failure)'
    value: ${{ steps.test-result.outputs.result }}
  coverage:
    description: 'Coverage percentage'
    value: ${{ steps.coverage.outputs.percentage }}

runs:
  using: 'composite'
  steps:
    - name: Setup Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ inputs.go-version }}
        cache: true

    - name: Create test directories
      shell: bash
      run: |
        mkdir -p coverage reports artifacts
        echo "ðŸ“ Test directories created"

    - name: Determine test packages
      id: packages
      shell: bash
      run: |
        echo "ðŸ” Determining test packages for type: ${{ inputs.test-type }}"

        case "${{ inputs.test-type }}" in
          "unit")
            PACKAGES="./pkg/... ./tests/unit/..."
            TEST_ARGS="-tags=unit"
            ;;
          "integration")
            PACKAGES="./tests/integration/..."
            TEST_ARGS="-tags=integration"
            ;;
          "e2e")
            PACKAGES="./tests/e2e/..."
            TEST_ARGS="-tags=e2e"
            ;;
          "all")
            PACKAGES="./..."
            TEST_ARGS=""
            ;;
          *)
            echo "âŒ Unknown test type: ${{ inputs.test-type }}"
            exit 1
            ;;
        esac

        # Add custom tags if provided
        if [[ -n "${{ inputs.test-tags }}" ]]; then
          if [[ -n "$TEST_ARGS" ]]; then
            TEST_ARGS="$TEST_ARGS,${{ inputs.test-tags }}"
          else
            TEST_ARGS="-tags=${{ inputs.test-tags }}"
          fi
        fi

        echo "packages=$PACKAGES" >> $GITHUB_OUTPUT
        echo "test-args=$TEST_ARGS" >> $GITHUB_OUTPUT

        echo "âœ… Test configuration:"
        echo "  Packages: $PACKAGES"
        echo "  Args: $TEST_ARGS"

    - name: Setup integration test dependencies
      if: contains(inputs.test-type, 'integration') || contains(inputs.test-type, 'e2e')
      shell: bash
      run: |
        echo "ðŸ”§ Setting up integration test dependencies..."

        # Load versions from config or use provided values
        if [[ -n "${{ inputs.vault-version }}" ]]; then
          VAULT_VERSION="${{ inputs.vault-version }}"
        else
          VAULT_VERSION=$(grep -A5 "vault:" tests/config/versions.yaml | grep "default:" | cut -d'"' -f2 2>/dev/null || echo "1.19.0")
        fi

        if [[ -n "${{ inputs.k3s-version }}" ]]; then
          K3S_VERSION="${{ inputs.k3s-version }}"
        else
          K3S_VERSION=$(grep -A5 "k3s:" tests/config/versions.yaml | grep "default:" | cut -d'"' -f2 2>/dev/null || echo "v1.30.8-k3s1")
        fi

        echo "VAULT_VERSION=$VAULT_VERSION" >> $GITHUB_ENV
        echo "K3S_VERSION=$K3S_VERSION" >> $GITHUB_ENV

        echo "âœ… Integration test versions:"
        echo "  Vault: $VAULT_VERSION"
        echo "  K3s: $K3S_VERSION"

    - name: Run tests
      id: run-tests
      shell: bash
      run: |
        echo "ðŸ§ª Running ${{ inputs.test-type }} tests..."

        # Build test command
        CMD="go test -v"

        # Add parallel execution
        CMD="$CMD -parallel=${{ inputs.parallel }}"

        # Add timeout
        CMD="$CMD -timeout=${{ inputs.timeout }}"

        # Add race detection
        if [[ "${{ inputs.race-detection }}" == "true" ]]; then
          CMD="$CMD -race"
        fi

        # Add coverage
        if [[ "${{ inputs.coverage }}" == "true" ]]; then
          CMD="$CMD -coverprofile=coverage/coverage.out -covermode=atomic"
        fi

        # Add test args
        if [[ -n "${{ steps.packages.outputs.test-args }}" ]]; then
          CMD="$CMD ${{ steps.packages.outputs.test-args }}"
        fi

        # Add packages
        CMD="$CMD ${{ steps.packages.outputs.packages }}"

        echo "Executing: $CMD"

        # Run tests with proper error handling
        if $CMD 2>&1 | tee reports/test-output.log; then
          echo "result=success" >> $GITHUB_OUTPUT
          echo "âœ… Tests completed successfully"
        else
          echo "result=failure" >> $GITHUB_OUTPUT
          echo "âŒ Tests failed"
          exit 1
        fi

    - name: Generate test summary
      id: summary
      if: always()
      shell: bash
      run: |
        echo "ðŸ“Š Generating test summary..."

        # Parse test results
        TOTAL_TESTS=$(grep -c "^=== RUN" reports/test-output.log 2>/dev/null || echo "0")
        PASSED_TESTS=$(grep -c "--- PASS:" reports/test-output.log 2>/dev/null || echo "0")
        FAILED_TESTS=$(grep -c "--- FAIL:" reports/test-output.log 2>/dev/null || echo "0")
        SKIPPED_TESTS=$(grep -c "--- SKIP:" reports/test-output.log 2>/dev/null || echo "0")

        # Generate summary
        SUMMARY="## ðŸ§ª Test Results (${{ inputs.test-type }})\n\n"
        SUMMARY="${SUMMARY}| Metric | Count |\n"
        SUMMARY="${SUMMARY}|--------|-------|\n"
        SUMMARY="${SUMMARY}| Total | $TOTAL_TESTS |\n"
        SUMMARY="${SUMMARY}| Passed | $PASSED_TESTS |\n"
        SUMMARY="${SUMMARY}| Failed | $FAILED_TESTS |\n"
        SUMMARY="${SUMMARY}| Skipped | $SKIPPED_TESTS |\n"

        echo "report<<EOF" >> $GITHUB_OUTPUT
        echo -e "$SUMMARY" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        # Add to step summary
        echo -e "$SUMMARY" >> $GITHUB_STEP_SUMMARY

    - name: Process coverage
      id: coverage
      if: inputs.coverage == 'true' && always()
      shell: bash
      run: |
        if [[ -f "coverage/coverage.out" ]]; then
          echo "ðŸ“ˆ Processing coverage data..."

          # Generate coverage report
          go tool cover -html=coverage/coverage.out -o coverage/coverage.html
          go tool cover -func=coverage/coverage.out > coverage/coverage.txt

          # Extract coverage percentage
          COVERAGE=$(go tool cover -func=coverage/coverage.out | grep "total:" | awk '{print $3}' | sed 's/%//')
          echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT

          echo "âœ… Coverage: $COVERAGE%"

          # Add coverage to summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Coverage: $COVERAGE%" >> $GITHUB_STEP_SUMMARY
        else
          echo "âš ï¸ No coverage data found"
          echo "percentage=0" >> $GITHUB_OUTPUT
        fi

    - name: Upload coverage to Codecov
      if: inputs.upload-coverage == 'true' && inputs.coverage == 'true'
      uses: codecov/codecov-action@v4
      with:
        file: coverage/coverage.out
        flags: ${{ inputs.test-type }}tests
        name: ${{ inputs.test-type }}-test-coverage
        fail_ci_if_error: false

    - name: Upload test artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ inputs.test-type }}-${{ github.run_number }}
        path: |
          coverage/
          reports/
          artifacts/
          *.log
        retention-days: 14

    - name: Set test result
      id: test-result
      if: always()
      shell: bash
      run: |
        if [[ "${{ steps.run-tests.outputs.result }}" == "success" ]]; then
          echo "result=success" >> $GITHUB_OUTPUT
        else
          echo "result=failure" >> $GITHUB_OUTPUT
        fi

    - name: Clean up test environment
      if: always() && (contains(inputs.test-type, 'integration') || contains(inputs.test-type, 'e2e'))
      shell: bash
      run: |
        echo "ðŸ§¹ Cleaning up test environment..."

        # Clean up any remaining containers
        docker system prune -f --volumes --filter "label=org.testcontainers.sessionId" 2>/dev/null || true

        # Clean up k3d clusters if any
        k3d cluster delete --all 2>/dev/null || true

        echo "âœ… Test environment cleaned up"
